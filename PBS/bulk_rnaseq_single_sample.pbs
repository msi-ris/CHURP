#!/bin/bash -l
#PBS -l nodes=1:ppn=8,mem=16gb,walltime=24:00:00

set -v
set -e
set -u
set -o pipefail

# Export the PS4 variable for the trace
export PS4='[$(date "+%F %T")] Line ${LINENO}: '

# Check the major version of the pipeline. If they mismatch, then quit with an error
PIPELINE_VERSION="0"
SAMPLESHEET_VERSION=$(tail -n 1 "${SampleSheet}" | sed -E 's/#//g')
if [ "${SAMPLESHEET_VERSION}" -ne "${PIPELINE_VERSION}" ]
then
    echo "${SampleSheet} is incompatible with this version of gopher-pipelines."
    echo "${SampleSheet} was generated with version ${SAMPLESHEET_VERSION}, and this script requires ${PIPELINE_VERSION}."
    exit 100
fi

# Parse SampleSheet using $PBS_ARRAYID
# Assume there is a header line, so for ID n, the sample is n+1
# Sample Sheet: SampleNM, R1, R2, Trim (yes or no), TrimmomaticOption, Hisat2Index, Hisat2Option, GTF/GFF
IN=$(head -n "${PBS_ARRAYID}" "${SampleSheet}" | tail -1)
# handle empty line and comment line. We return a 0 exit status because we do not
# want a comment/blank line in the samplesheet to hold up the array jobs
[ -z "${IN// }" ] && echo "hit an empty line in sample sheet" && exit 0
[ "$IN" = "#.*" ] && echo "hit a comment line in sample sheet" && exit 0
while IFS="|" read -ra OPTS; do 
    SAMPLENM=${OPTS[0]}
    EXPR_GROUP=${OPTS[1]}
    R1FILE=${OPTS[2]}
    R2FILE=${OPTS[3]}
    OUTDIR=${OPTS[4]}
    WORKDIR=${OPTS[5]}
    TRIM=${OPTS[6]}
    RMDUP=${OPTS[7]}
    TRIMOPTS=${OPTS[8]}
    HISAT2INDEX=${OPTS[9]}
    HISAT2OPTS=${OPTS[10]}
    UNSTRANDED=${OPTS[11]}
    GTFFILE=${OPTS[12]}
done <<< "$IN"

# Start the trace. In this case, we use file descriptor 5 to avoid clobbering
# any other fds that are in use
LOGDIR="${OUTDIR}/Logs"
mkdir -p "${LOGDIR}"
TRACE_FNAME="${LOGDIR}/${SAMPLENM}_Trace.log"
LOG_FNAME="${LOGDIR}/${SAMPLENM}_Analysis.log"
exec 5> "${TRACE_FNAME}"
export BASH_XTRACEFD=5
set -x

# This is annoying to see, so we will exclude it from verbose outout
set +v
# load necessary modules
module load hisat2/2.1.0
module load fastqc/0.11.7
module load trimmomatic/0.33
module load java/jdk1.8.0_144
module load samtools/1.7
module load picard/2.9.0
module load R/3.5.0

# And re-enable verbosity here
set -v
module list -t
module list -t 2>> "${LOG_FNAME}"

# Check if we are running in paired or single end mode
if [ -z "${R2FILE}" ]
then
    PE="false"
    echo "# No R2 file detected; running ${SAMPLENM} as single-end" >> "${LOG_FNAME}"
else
    PE="true"
    echo "# R2 file detected; running ${SAMPLENM} as paired-end" >> "${LOG_FNAME}"
fi

# set working directory
mkdir -p "${WORKDIR}/singlesamples/${SAMPLENM}" && cd "${WORKDIR}/singlesamples/${SAMPLENM}"

# check whether to purge files or not. $PURGE will be parsed by command line
if [ "${PURGE}" = "true" ]; then
    echo "# $(date '+%F %T'): PURGE=true; re-running all analyses." >> "${LOG_FNAME}"
    find . -name '*.done' -delete
fi

# start workflow with check point
[ -f "${SAMPLENM}.done" ] && echo "found done analysis, exit" && exit $?

# Set Up a log file instead (?)
if [ ! -f fastqc.done ]; then
    if [ "${PE}" = "true" ]
    then
        echo "# $(date '+%F %T'): Running fastqc on ${R1FILE} and ${R2FILE}." >> "${LOG_FNAME}"
        fastqc \
            -t 2 \
            --extract \
            --outdir="${WORKDIR}/singlesamples/${SAMPLENM}" \
            "${R1FILE}" \
            "${R2FILE}" \
            2>> "${LOG_FNAME}" \
        && touch fastqc.done
    else
        echo "# $(date '+%F %T'): Running fastqc on ${R1FILE}." >> "${LOG_FNAME}"
        fastqc \
            --extract \
            --outdir="${WORKDIR}/singlesamples/${SAMPLENM}" \
            "${R1FILE}" \
            2>> "${LOG_FNAME}" \
            && touch fastqc.done
    fi
fi

# The fastqc files are auto-extracted, so we search for the directories that
# end in '_fastqc', pull out the total number of reads, then throw away the
# directory
for fastqc_out_dir in $(find "${WORKDIR}/singlesamples/${SAMPLENM}" -maxdepth 1 -type d -name '*_fastqc')
do
    read_no=$(basename "${fastqc_out_dir}" | sed -nr 's/.*(R[1|2])_001_fastqc*/\\1/p')
    if [ -z "${read_no}" ]
    then
        read_no="1"
    fi
    out_pref="${SAMPLENM}_${read_no}.raw_readcount.txt"
    echo "${SAMPLENM} $(grep '^Total Sequences' ${fastqc_out_dir}/fastqc_data.txt | cut -f 2)" > "${out_pref}"
    awk '/>>Per base sequence quality/{flag=1; next} />>END_MODULE/{flag=0} flag' \
        "${fastqc_out_dir}/fastqc_data.txt" \
        | sed -e 's/ /./g' \
        > "${WORKDIR}/singlesamples/${SAMPLENM}/${SAMPLENM}_${read_no}_raw_quals.txt"
    rm -rf "${fastqc_out_dir}.processed"
    mv -f "${fastqc_out_dir}" "${fastqc_out_dir}.processed"
done

# To use -basein option, fastq file must be in format *_R1_*.fastq and *_R2_*.fastq
# trimmomatic can handle the -basein and -baseout options if there is only one
# read (single end).
if [ "${TRIM}" = "yes" ]; then
    if [ ! -f trimmomatic.done ]; then
        if [ "${PE}" = "true" ]
        then
            echo "# $(date '+%F %T'): Running trimmomatic on ${R1FILE} and ${R2FILE}." >> "${LOG_FNAME}"
            java -jar "${TRIMMOMATIC}"/trimmomatic.jar \
                PE \
                -threads "${PBS_NUM_PPN}" \
                -basein "${R1FILE}" \
                -baseout "${SAMPLENM}" \
                $(echo "${TRIMOPTS}" | envsubst) \
                2>> "${LOG_FNAME} \
                && touch trimmomatic.done
        else
            echo "# $(date '+%F %T'): Running trimmomatic on ${R1FILE}." >> "${LOG_FNAME}"
            java -jar "${TRIMMOMATIC}"/trimmomatic.jar \
                SE \
                -threads "${PBS_NUM_PPN}" \
                "${R1FILE}" \
                "${SAMPLENM}_trimmed" \
                $(echo "${TRIMOPTS}" | envsubst) \
                2>> "${LOG_FNAME} \
                && touch trimmomatic.done
        fi
    fi
    if [ ! -f fastqc.trim.done ]; then
        if [ "${PE}" = "true" ]
        then
            echo "# $(date '+%F %T'): Running fastqc on trimmed fastq files." >> "${LOG_FNAME}"
            fastqc \
                -t 2 \
                --extract \
                --outdir="${WORKDIR}/singlesamples/${SAMPLENM}" \
                "${SAMPLENM}_1P" \
                "${SAMPLENM}_2P" \
                2>> "${LOG_FNAME}" \
                && touch fastqc.trim.done
        else
            echo "# $(date '+%F %T'): Running fastqc on trimmed fastq file." >> "${LOG_FNAME}"
            fastqc \
                --extract \
                --outdir="${WORKDIR}/singlesamples/${SAMPLENM}" \
                "${SAMPLENM}_trimmed" \
                2>> "${LOG_FNAME}" \
                && touch fastqc.trim.done
        fi
    fi
fi

for fastqc_out_dir in $(find "${WORKDIR}/singlesamples/${SAMPLENM}" -maxdepth 1 -type d -name '*_fastqc')
do
    read_no=$(basename "${fastqc_out_dir}" | sed -nr 's/.*([1|2])P_fastqc/\\1/p')
    # If the files are single-end, then $read_no is empty
    if [ -z "${read_no}" ]
    then
        read_no="1"
    fi
    out_pref="${SAMPLENM}_${read_no}.trimmed_readcount.txt"
    echo "${SAMPLENM} $(grep '^Total Sequences' ${fastqc_out_dir}/fastqc_data.txt | cut -f 2)" > "${out_pref}"
    awk '/>>Per base sequence quality/{flag=1; next} />>END_MODULE/{flag=0} flag' \
        "${fastqc_out_dir}/fastqc_data.txt" \
        | sed -e 's/ /./g' \
        > "${WORKDIR}/singlesamples/${SAMPLENM}/${SAMPLENM}_R${read_no}_trim_quals.txt"
    rm -rf "${fastqc_out_dir}.processed"
    mv -f "${fastqc_out_dir}" "${fastqc_out_dir}.processed"
done

if [ ! -f hisat2.done ]; then
    if [ "${TRIM}" = "yes" ]; then
        if [ "${PE}" = "true" ]
        then
            echo "# $(date '+%F %T'): Aligning trimmed reads with HISAT2." >> "${LOG_FNAME}"
            # This string is so ugly because we we have to quote the arguments to hisat2 in a weird way to protect them from splitting
            hisat2 \
                ${HISAT2OPTS} \
                -x "'${HISAT2INDEX}'" \
                -1 "'${SAMPLENM}_1P'" \
                -2 "'${SAMPLENM}_2P'" \
                -S "${SAMPLENM}.sam" \
                2> alignment.summary \
                && touch hisat2.done
        else
            echo "# $(date '+%F %T'): Aligning trimmed reads with HISAT2." >> "${LOG_FNAME}"
            hisat2 \
                ${HISAT2OPTS} \
                -x "'${HISAT2INDEX}'" \
                -U "'${SAMPLENM}_trimmed'" \
                -S "${SAMPLENM}.sam" \
                2> alignment.summary \
                && touch hisat2.done
        fi
    else
        # Hisat2 chokes on our quoted reads files if they are gzipped. This is
        # only an issue if we are not trimming because by default we are not
        # gzipping the trimmed reads.
        if [ "${PE}" = "true" ]
        then
            echo "# $(date '+%F %T'): Aligning reads with HISAT2." >> "${LOG_FNAME}"
            hisat2 \
                ${HISAT2OPTS} \
                -x "'${HISAT2INDEX}'" \
                -1 <(gzip -cd "${R1FILE}" || cat "${R1FILE}") \
                -2 <(gzip -cd "${R2FILE}" || cat "${R2FILE}") \
                -S "${SAMPLENM}.sam" \
                2> alignment.summary \
                && touch hisat2.done
        else
            echo "# $(date '+%F %T'): Aligning reads with HISAT2." >> "${LOG_FNAME}"
            hisat2 \
                ${HISAT2OPTS} \
                -x "'${HISAT2INDEX}'" \
                -U <(gzip -cd "${R1FILE}" || cat "${R1FILE}") \
                -S "${SAMPLENM}.sam" \
                2> alignment.summary \
                && touch hisat2.done
        fi
    fi
fi

# Stick the alignment summary onto the analysis log
cat alignment.summary 2>> "${LOG_FNAME}"

# use samtools to remove unmapped reads, could be done in picard too.
if [ ! -f samtools.done ]; then
    if [ "${RMDUP}" = "yes" ]; then
        echo "# $(date '+%F %T'): Sorting by read name and removing duplicates from HISAT2 alignment." >> "${LOG_FNAME}"
        samtools view \
            -bh \
            -F 4 \
            -q 60 \
            -@ ${PBS_NUM_PPN} \
            "${SAMPLENM}.sam" \
            | samtools sort \
            -n \
            -o "${SAMPLENM}.sorted.bam" \
            -@ ${PBS_NUM_PPN} \
            -O bam \
            -T temp
        samtools rmdup \
            "${SAMPLENM}.sorted.bam" \
            "${SAMPLENM}.sorted.rmdup.bam"
        # Sort the bam by coordinate, too
        samtools sort \
            -o "${SAMPLENM}_Coord.sorted.rmdup.bam" \
            -@ ${PBS_NUM_PPN} \
            -O bam \
            -T temp \
            "${SAMPLENM}.sorted.rmdup.bam"
        samtools index "${SAMPLENM}_Coord.sorted.rmdup.bam"
        # Generate some summaries of the bam here
        samtools stats "${SAMPLENM}_Coord.sorted.rmdup.bam" > "${SAMPLENM}_bamstats.txt"
        FINAL_BAM="${SAMPLENM}.sorted.rmdup.bam"
        COORD_BAM="${SAMPLENM}_Coord.sorted.rmdup.bam"
        COORD_BAI="${SAMPLENM}_Coord.sorted.rmdup.bam.bai"
        touch samtools.done
    else
        echo "# $(date '+%F %T'): Sorting by read name" >> "${LOG_FNAME}"
        samtools view \
            -bh \
            -F 4 \
            -q 60\
             -@ ${PBS_NUM_PPN} \
             "${SAMPLENM}.sam" \
             | samtools sort \
             -n \
             -o "${SAMPLENM}.sorted.bam" \
             -@ ${PBS_NUM_PPN} \
             -O bam \
             -T temp
        # Sort the bam by coordinate, too
        samtools sort \
            -o "${SAMPLENM}_Coord.sorted.bam" \
            -@ ${PBS_NUM_PPN} \
            -O bam \
            -T temp \
            "${SAMPLENM}.sorted.bam"
        samtools index "${SAMPLENM}_Coord.sorted.bam"
        samtools stats "${SAMPLENM}_Coord.sorted.bam" > "${SAMPLENM}_bamstats.txt"
        FINAL_BAM="${SAMPLENM}.sorted.bam"
        COORD_BAM="${SAMPLENM}_Coord.sorted.bam"
        COORD_BAI="${SAMPLENM}_Coord.sorted.bam.bai"
        touch samtools.done
    fi
fi

# Use picard to collect the insert size metrics, but only if paired end
if [ "${PE}" = "true" ]
then
    echo "# $(date '+%F %T'): Collecting insert size metrics for ${SAMPLENM}" >> "${LOG_FNAME}"
    mkdir -p "${OUTDIR}/InsertSizeMetrics"
    mkdir -p "${WORKDIR}/singlesamples/${SAMPLENM}/picard_tmp"
    _JAVA_OPTIONS="-Djava.io.tmpdir=${WORKDIR}/singlesamples/${SAMPLENM}/picard_tmp" ${PTOOL}/picard.jar \
        CollectInsertSizeMetrics \
        I="${WORKDIR}/singlesamples/${SAMPLENM}/${FINAL_BAM}" \
        O="${OUTDIR}/InsertSizeMetrics/${SAMPLENM}_metrics.txt" \
        H="${OUTDIR}/InsertSizeMetrics/${SAMPLENM}_hist.pdf" \
        2>> "${LOG_FNAME}"
    # Extract the mean, median, standard deviation from the metrics file
    grep \
        -A 1 \
        '^MEDIAN_INSERT_SIZE' \
        "${OUTDIR}/InsertSizeMetrics/${SAMPLENM}_metrics.txt" \
        | tail -n 1 \
        | cut -f 1,5,6,9,11,15,17 \
        > "${WORKDIR}/singlesamples/${SAMPLENM}/IS_Stats.txt"
fi

# Use awk to pick apart the alignment summary
if [ "${PE}" = "true" ]
then
    TOTAL_READS=$(awk '/Total pairs:/ {print $NF}' alignment.summary)
    UNMAP=$(awk '/Aligned concordantly or discordantly 0 time/ {F=NF-1; print $F}' alignment.summary)
    SINGLE_MAP=$(awk '/Aligned concordantly 1 time/ {F=NF-1; print $F}' alignment.summary)
    MULTI_MAP=$(awk '/Aligned concordantly >1 times/ {F=NF-1; print $F}' alignment.summary)
    DISCO_MAP=$(awk '/Aligned discordantly 1 time/ {F=NF-1; print $F}' alignment.summary)
else
    TOTAL_READS=$(awk '/Total reads:/ {print $NF}' alignment.summary)
    UNMAP=$(awk '/Aligned 0 time/ {F=NF-1; print $F}' alignment.summary)
    SINGLE_MAP=$(awk '/Aligned 1 time/ {F=NF-1; print $F}' alignment.summary)
    MULTI_MAP=$(awk '/Aligned >1 times/ {F=NF-1; print $F}' alignment.summary)
    DISCO_MAP="NA"
fi
echo "${SAMPLENM} ${TOTAL_READS} ${UNMAP} ${SINGLE_MAP} ${MULTI_MAP} ${DISCO_MAP}" > "hisat_map_summary.txt"

# the final step is to link the sorted.rmdup.bam file to the allsamples/
# directory, as just the samplename. This is a bit of a hack to get featureCounts
# to not print huge paths as samplenames
echo "# $(date '+%F %T'): Linking ${SAMPLENM} into ${WORKDIR}/allsamples" >> "${LOG_FNAME}"
mkdir -p "${WORKDIR}/allsamples"
ln -sf "${WORKDIR}/singlesamples/${SAMPLENM}/${FINAL_BAM}" "${WORKDIR}/allsamples/${SAMPLENM}"

echo "$ $(date '+%F %T'): Linking coordinate-sorted BAMs into ${OUTDIR}/Coordinate_Sorted_BAMs/" >> "${LOG_FNAME}"
mkdir -p "${OUTDIR}/Coordinate_Sorted_BAMs"
ln -sf "${WORKDIR}/singlesamples/${SAMPLENM}/${COORD_BAM}" "${OUTDIR}/Coordinate_Sorted_BAMs/${COORD_BAM}"
ln -sf "${WORKDIR}/singlesamples/${SAMPLENM}/${COORD_BAI}" "${OUTDIR}/Coordinate_Sorted_BAMs/${COORD_BAI}"

echo "# $(date '+%F %T'): Finished processing ${SAMPLENM}." >> "${LOG_FNAME}"
touch "${SAMPLENM}.done"

# And close the file descriptor we were using
exec 5>&-
