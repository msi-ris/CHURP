#!/bin/bash
#PBS -l nodes=1:ppn=8,mem=16gb,walltime=8:00:00

set -v
set -e
set -u
set -o pipefail

# Export the PS4 variable for the trace
# Taken from https://wiki.bash-hackers.org/scripting/debuggingtips
export PS4='+(${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'

# Check for PBS/Samplesheet version agreement
PIPELINE_VERSION="0"
SAMPLESHEET_VERSION=$(tail -n 1 "${SampleSheet}" | sed -E 's/#//g')
if [ "${SAMPLESHEET_VERSION}" -ne "${PIPELINE_VERSION}" ]
then
    echo "${SampleSheet} is incompatible with this version of CHURP."
    echo "${SampleSheet} was generated with version ${SAMPLESHEET_VERSION}, and this script requires ${PIPELINE_VERSION}."
    exit 100
fi

# Read the first line of the samplesheet to get the working directory and the
# GTF. This is not super elegant, but it works with the samplesheet format
IN=$(head -n 1 "${SampleSheet}")
# handle empty line and comment line. We return a 0 exit status because we do not
# want a comment/blank line in the samplesheet to hold up the array jobs
[ -z "${IN// }" ] && echo "hit an empty line in sample sheet" && exit 0
[ "$IN" = "#.*" ] && echo "hit a comment line in sample sheet" && exit 0
while IFS="|" read -ra OPTS; do 
    SAMPLENM=${OPTS[0]}
    EXPR_GROUP=${OPTS[1]}
    R1FILE=${OPTS[2]}
    R2FILE=${OPTS[3]}
    OUTDIR=${OPTS[4]}
    WORKDIR=${OPTS[5]}
    TRIM=${OPTS[6]}
    RMDUP=${OPTS[7]}
    TRIMOPTS=${OPTS[8]}
    HISAT2INDEX=${OPTS[9]}
    HISAT2OPTS=${OPTS[10]}
    STRAND=${OPTS[11]}
    GTFFILE=${OPTS[12]}
done <<< "$IN"

# this is annoying to see in the verbose log
set +v
# load necessary modules
module load R/3.5.0
module load python/3.6.3
set -v
# Make directories for the output files. We want to keep the outdir organized
LOGDIR="${OUTDIR}/Logs"
COUNTSDIR="${OUTDIR}/Counts"
PLOTSDIR="${OUTDIR}/Plots"
DEGDIR="${OUTDIR}/DEGs"

mkdir -p "${LOGDIR}" "${COUNTSDIR}" "${PLOTSDIR}" "${DEGDIR}"

# Print the loaded modules to stderr and a log file
module list -t
TRACE_FNAME="${LOGDIR}/BulkRNASeq_Trace.log"
LOG_FNAME="${LOGDIR}/BulkRNASeq_Summary.log"
exec 5> "${TRACE_FNAME}"
export BASH_XTRACEFD=5
set -x
echo "# $(date '+%F %T'): Summary started" > "${LOG_FNAME}"
echo '#BEGIN_MODULES' >> "${LOG_FNAME}"
module list -t 2>> "${LOG_FNAME}"
echo '#END_MODULES' >> "${LOG_FNAME}"


if [ -z "${R2FILE}" ]
then
    PE="false"
    echo "# No R2 file detected; running ${SAMPLENM} as single-end" >> "${LOG_FNAME}"
    echo "# NOTE! We are assuming that all samples were subject to the same preparation and sequencing protocols." >> "${LOG_FNAME}"
    echo "# NOTE! We do not support mixing of single-end and paired-end samples for counts and differential expression testing." >> "${LOG_FNAME}"
else
    PE="true"
    echo "# R2 file detected; running ${SAMPLENM} as paired-end" >> "${LOG_FNAME}"
    echo "# NOTE! We are assuming that all samples were subject to the same preparation and sequencing protocols." >> "${LOG_FNAME}"
    echo "# NOTE! We do not support mixing of single-end and paired-end samples for counts and differential expression testing." >> "${LOG_FNAME}"
fi

# Set the R_LIBS_USER variable here. This is where packages will be loaded from
# within R
echo "# $(date '+%F %T'): Adding /home/msistaff/public/CHURP_Deps/v${PIPELINE_VERSION}/R to R_LIBS_USER" >> "${LOG_FNAME}"
export R_LIBS_USER="/home/msistaff/public/CHURP_Deps/v${PIPELINE_VERSION}/R"

# Set the path to the featureCounts executable.
echo "# $(date '+%F %T'): Using counting reads with featureCounts v. 1.6.2" >> "${LOG_FNAME}"
FEATURECOUNTS="/home/msistaff/public/CHURP_Deps/v${PIPELINE_VERSION}/Supp/subread-1.6.2-Linux-x86_64/bin/featureCounts"
mkdir -p "${WORKDIR}/allsamples" && cd "${WORKDIR}/allsamples"

# Use featureCounts to make a merged counts matrix
echo "# $(date '+%F %T'): Making a counts matrix for all samples." >> "${LOG_FNAME}"
BAM_LIST=($(find . -type l -exec basename {} \\;| sort -V))
if [ "${PE}" = "true" ]
then
    echo "# $(date '+%F %T'): Library is paired-end with strand ${STRAND}." >> "${LOG_FNAME}"
    "${FEATURECOUNTS}" \
        -a "${GTFFILE}" \
        -T ${PBS_NUM_PPN} \
        -B \
        -p \
        -Q 10 \
        -s "${STRAND}" \
        -R CORE \
        -o subread_counts.txt \
        "${BAM_LIST[@]}"
else
    echo "# $(date '+%F %T'): Library is single-end with strand ${STRAND}" >> "${LOG_FNAME}"
    "${FEATURECOUNTS}" \
        -a "${GTFFILE}" \
        -T ${PBS_NUM_PPN} \
        -Q 10 \
        -s "${STRAND}" \
        -R CORE \
        -o subread_counts.txt \
        "${BAM_LIST[@]}"
fi

# Summarize the merged count data, including descriptive summaries and differential expression tests if >1 group present.
echo "# $(date '+%F %T'): Running edgeR analysis on counts" >> "${LOG_FNAME}"
Rscript \
    "${RSUMMARY}" \
    "${OUTDIR}" \
    "${WORKDIR}" \
    "${SampleSheet}" \
    "${WORKDIR}/allsamples/subread_counts.txt" \
    "${MINLEN}" \
    "${MINCPM}" \
    &> Rout.txt

echo "# ----- Output from ${RSUMMARY} below" >> "${LOG_FNAME}"
cat Rout.txt >> "${LOG_FNAME}"
echo "# ----- End output from ${RSUMMARY}" >> "${LOG_FNAME}"

# Copy the merged counts into the output directory. The -u option to cp causes
# the copy to happen only if the source file is newer than the destination file
# or if the destination does not exist.
echo "# $(date '+%F %T'): Copying merged counts matrix and summary into ${COUNTSDIR}" >> "${LOG_FNAME}"
cp -u subread_counts.txt "${COUNTSDIR}/subread_counts.txt"
cp -u subread_counts.txt.summary "${COUNTSDIR}/subread_counts.txt.summary"

# We also want to keep the sorted BAM files and the GTF used for counts, in
# case the user wants to go back to it
echo "# $(date '+%F %T'): Copying GTF into ${OUTDIR}." >> "${LOG_FNAME}"
cp -u "${GTFFILE}" "${OUTDIR}"

# AWK command from S. Munro to make a translation table fo Ensembl IDs and
# gene names
echo "# $(date '+%F %T'): Generating translation table of gene name and Ensembl ID." >> "${LOG_FNAME}"
awk -F '\\t' '$3 == "gene" { print $9 }' <(gzip -cd "${GTFFILE}" || cat "${GTFFILE}") | tr -d ';"' | awk -F ' ' -v OFS='\\t' '{print $2,$6}' > "${OUTDIR}/gene_id_gene_name_map.txt"
# This is a slower but more general command to get gene_id and gene_name
# awk -F'\t' '$3 == "gene" {print $9}' | awk -F';' '{for(i = 1; i <= NF; i++) { if( $i ~ /gene_id/ ) {split($i,GI," ")}; if( $i ~ /gene_name/ ) {split($i,GN," ")} }; print GI[2]"\t"GN[2]}' | sed -e 's/"//g'

# Link the work directories to the output directory
rm -f "${OUTDIR}/singlesamples_work_directory" "${OUTDIR}/allsamples_work_directory"
ln -sf "${WORKDIR}/singlesamples" "${OUTDIR}/singlesamples_work_directory"
ln -sf "${WORKDIR}/allsamples" "${OUTDIR}/allsamples_work_directory"

# Prepare to generate HTML report by making unified files for everything. We
# will have to iterate over every sample
# Remove old summary files
rm -f \
    "${WORKDIR}/allsamples/Read_Counts.txt" \
    "${WORKDIR}/allsamples/Samtools_Stats.txt" \
    "${WORKDIR}/allsamples/HISAT_Stats.txt" \
    "${WORKDIR}/allsamples/IS_Stats.txt" \
    "${WORKDIR}/allsamples/Dup_Stats.txt" \
    "${WORKDIR}/allsamples/RNASeq_Metrics.txt"
# Remove from the instance of the first blank line to the end of the file
OFFSET=$(cut -f 1 -d '|' "${SampleSheet}" | grep -nE '^$' | head -n 1 | sed -e 's/://g')
SNAMES=($(cut -f 1 -d '|' "${SampleSheet}" | sed -e "${OFFSET},\\$d"))
for sample in "${SNAMES[@]}"
do
    echo "# $(date '+%F %T'): Collecting summaries for ${sample}" >> "${LOG_FNAME}"
    # Make the read counts files
    RAW_R1=$(find "${WORKDIR}/singlesamples/${sample}" -maxdepth 1 -type f -name '*R1*.raw_readcount.txt')
    RAW_R2=$(find "${WORKDIR}/singlesamples/${sample}" -maxdepth 1 -type f -name '*R2*.raw_readcount.txt')
    R1_COUNT=$(awk '{print $NF}' "${RAW_R1}")
    if [ -z "${RAW_R2}" ]
    then
        R2_COUNT="NA"
    else
        R2_COUNT=$(awk '{print $NF}' "${RAW_R2}")
    fi
    TRIMMED_R1=$(find "${WORKDIR}/singlesamples/${sample}" -maxdepth 1 -type f -name '*1.trimmed_readcount.txt')
    TRIMMED_R2=$(find "${WORKDIR}/singlesamples/${sample}" -maxdepth 1 -type f -name '*2.trimmed_readcount.txt')
    if [ -z "${TRIMMED_R1}" ]
    then
        TR1_COUNT="NA"
    else
        TR1_COUNT=$(awk '{print $NF}' "${TRIMMED_R1}")
    fi
    if [ -z "${TRIMMED_R2}" ]
    then
        TR2_COUNT="NA"
    else
        TR2_COUNT=$(awk '{print $NF}' "${TRIMMED_R2}")
    fi
    echo -e "${sample}\\t${R1_COUNT}\\t${R2_COUNT}\\t${TR1_COUNT}\\t${TR2_COUNT}" >> "${WORKDIR}/allsamples/Read_Counts.txt"
    # Get overall duplication stats
    R1_DUP=$(find "${WORKDIR}/singlesamples/${sample}" -maxdepth 1 -type f -name '*R1*_overall_dup.txt')
    R2_DUP=$(find "${WORKDIR}/singlesamples/${sample}" -maxdepth 1 -type f -name '*R2*_overall_dup.txt')
    TOT_R1_DUP=$(awk '{print $NF}' "${R1_DUP}")
    if [ -z "${R2_DUP}" ]
    then
        TOT_R2_DUP="NA"
    else
        TOT_R2_DUP=$(awk '{print $NF}' "${R2_DUP}")
    fi
    echo -e "${sample}\\t${TOT_R1_DUP}\\t${TOT_R2_DUP}" >> "${WORKDIR}/allsamples/Dup_Stats.txt"
    cat "${WORKDIR}/singlesamples/${sample}/hisat_map_summary.txt" >> "${WORKDIR}/allsamples/HISAT_Stats.txt"
    # Then, get alignment summary files
    BAMSTAT="${WORKDIR}/singlesamples/${sample}/${sample}_bamstats.txt"
    NMAPPED=$(grep '^SN' "${BAMSTAT}" | grep 'raw total sequences' | cut -f 3)
    DUPLICATED=$(grep '^SN' "${BAMSTAT}" | grep 'reads duplicated' | cut -f 3)
    MQ0=$(grep '^SN' "${BAMSTAT}" | grep 'reads MQ0' | cut -f 3)
    MAXLEN=$(grep '^SN' "${BAMSTAT}" | grep 'maximum length' | cut -f 3)
    AVGLEN=$(grep '^SN' "${BAMSTAT}" | grep 'average length' | cut -f 3)
    AVGQUAL=$(grep '^SN' "${BAMSTAT}" | grep 'average quality' | cut -f 3)
    echo -e "${sample}\\t${NMAPPED}\\t${DUPLICATED}\\t${MQ0}\\t${MAXLEN}\\t${AVGLEN}\\t${AVGQUAL}" >> "${WORKDIR}/allsamples/Samtools_Stats.txt"
    # Get the BBDuk rRNA screen stats
    echo -e "${sample}\\t$(grep '#Matched' ${WORKDIR}/singlesamples/${sample}/BBDuk_rRNA_Stats.txt | cut -f 2-3)" >> "${WORKDIR}/allsamples/rRNA_kmers.txt"
    # Then, get the insert size summaries. These are really simple.
    if [ -f "${WORKDIR}/singlesamples/${sample}/IS_Stats.txt" ]
    then
        echo -e "${sample}\\t$(cat ${WORKDIR}/singlesamples/${sample}/IS_Stats.txt)" >> "${WORKDIR}/allsamples/IS_Stats.txt"
    fi
    # And collect the RNAseq metrics into a single file for summarization
    echo -e "${sample}\\t$(cat ${WORKDIR}/singlesamples/${SAMPLENM}/rnaseq_metrics.txt)" >> "${WORKDIR}/allsamples/RNASeq_Metrics.txt"
done

# We will generate an HTML report
# This is an ugly workaround, but sidesteps the problem of write-locked public dirs for Rmarkdown/knitr
cp -u "${BULK_RNASEQ_REPORT}" "./Report.Rmd"
PATH=${PATH}:/panfs/roc/groups/14/msistaff/public/CHURP_Deps/v0/Supp/pandoc-2.3.1/bin Rscript -e "library(rmarkdown); rmarkdown::render('./Report.Rmd', output_file='"${OUTDIR}/Bulk_RNAseq_Report.html"', params=list(outdir='"${OUTDIR}"', workdir='"${WORKDIR}"', pipeline='"${PIPE_SCRIPT}"', samplesheet='"${SampleSheet}"'))"

echo "# $(date '+%F %T'): Done summarizing bulk RNAseq run" >> "${LOG_FNAME}"
# Close the trace file descriptor
exec 5>&-
